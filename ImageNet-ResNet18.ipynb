{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a4fbeeb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import shutil\n",
    "import time\n",
    "import warnings\n",
    "#os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"5\"\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.distributed as dist\n",
    "import torch.optim\n",
    "import torch.multiprocessing as mp\n",
    "import torch.utils.data\n",
    "import torch.utils.data.distributed\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.models as models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ca663a60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data loading code\n",
    "\n",
    "valdir = '/data/public/imagenet2012/val'\n",
    "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                 std=[0.229, 0.224, 0.225])\n",
    "\n",
    "batch_size = 256\n",
    "val_loader = torch.utils.data.DataLoader(\n",
    "    datasets.ImageFolder(valdir, transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        normalize,\n",
    "    ])),\n",
    "    batch_size=batch_size, shuffle=False,\n",
    "    num_workers=4, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "192e280e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(val_loader, model, criterion):\n",
    "    batch_time = AverageMeter('Time', ':6.3f')\n",
    "    losses = AverageMeter('Loss', ':.4e')\n",
    "    top1 = AverageMeter('Acc@1', ':6.2f')\n",
    "    top5 = AverageMeter('Acc@5', ':6.2f')\n",
    "    progress = ProgressMeter(\n",
    "        len(val_loader),\n",
    "        [batch_time, losses, top1, top5],\n",
    "        prefix='Test: ')\n",
    "\n",
    "    # switch to evaluate mode\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        end = time.time()\n",
    "        for i, (images, target) in enumerate(val_loader):\n",
    "           \n",
    "            images = images.cuda()\n",
    "            target = target.cuda()\n",
    "\n",
    "            # compute output\n",
    "            output = model(images)\n",
    "            loss = criterion(output, target)\n",
    "\n",
    "            # measure accuracy and record loss\n",
    "            acc1, acc5 = accuracy(output, target, topk=(1, 5))\n",
    "            losses.update(loss.item(), images.size(0))\n",
    "            top1.update(acc1[0], images.size(0))\n",
    "            top5.update(acc5[0], images.size(0))\n",
    "\n",
    "            # measure elapsed time\n",
    "            batch_time.update(time.time() - end)\n",
    "            end = time.time()\n",
    "\n",
    "            if i % 10 == 0:\n",
    "                progress.display(i)\n",
    "\n",
    "        # TODO: this should also be done with the ProgressMeter\n",
    "        print(' * Acc@1 {top1.avg:.3f} Acc@5 {top5.avg:.3f}'\n",
    "              .format(top1=top1, top5=top5))\n",
    "\n",
    "    return top1.avg\n",
    "\n",
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "    def __init__(self, name, fmt=':f'):\n",
    "        self.name = name\n",
    "        self.fmt = fmt\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "    def __str__(self):\n",
    "        fmtstr = '{name} {val' + self.fmt + '} ({avg' + self.fmt + '})'\n",
    "        return fmtstr.format(**self.__dict__)\n",
    "\n",
    "\n",
    "class ProgressMeter(object):\n",
    "    def __init__(self, num_batches, meters, prefix=\"\"):\n",
    "        self.batch_fmtstr = self._get_batch_fmtstr(num_batches)\n",
    "        self.meters = meters\n",
    "        self.prefix = prefix\n",
    "\n",
    "    def display(self, batch):\n",
    "        entries = [self.prefix + self.batch_fmtstr.format(batch)]\n",
    "        entries += [str(meter) for meter in self.meters]\n",
    "        print('\\t'.join(entries))\n",
    "\n",
    "    def _get_batch_fmtstr(self, num_batches):\n",
    "        num_digits = len(str(num_batches // 1))\n",
    "        fmt = '{:' + str(num_digits) + 'd}'\n",
    "        return '[' + fmt + '/' + fmt.format(num_batches) + ']'\n",
    "    \n",
    "def accuracy(output, target, topk=(1,)):\n",
    "    \"\"\"Computes the accuracy over the k top predictions for the specified values of k\"\"\"\n",
    "    with torch.no_grad():\n",
    "        maxk = max(topk)\n",
    "        batch_size = target.size(0)\n",
    "\n",
    "        _, pred = output.topk(maxk, 1, True, True)\n",
    "        pred = pred.t()\n",
    "        correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
    "\n",
    "        res = []\n",
    "        for k in topk:\n",
    "            correct_k = correct[:k].contiguous().view(-1).float().sum(0, keepdim=True)  # remove .contiguous() in low version torch\n",
    "            res.append(correct_k.mul_(100.0 / batch_size))\n",
    "        return res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4d2e75c",
   "metadata": {},
   "source": [
    "## ACM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3c889900",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "def arnold(img, key):\n",
    "    N, a, b, c, d = key  #  key=[1,1,1,1,2]\n",
    "    h, w = img.shape[: 2]\n",
    "    new_img = copy.deepcopy(img)\n",
    "\n",
    "    for i in range(N):\n",
    "        \n",
    "        for x in range(h):\n",
    "            \n",
    "            for y in range(w):\n",
    "                \n",
    "                nx = ((a * x + b * y) % w + w) % w\n",
    "                ny = ((c * x + d * y) % w + w) % w\n",
    "                nx = int(nx)\n",
    "                \n",
    "                ny = int(ny)\n",
    "                \n",
    "                new_img[nx, ny] = img[x, y]\n",
    "        img = copy.deepcopy(new_img)\n",
    "    return new_img\n",
    "\n",
    "\n",
    "def iarnold(img, key):\n",
    "    N, a, b, c, d = key\n",
    "\n",
    "    #matrix = np.mat([[a, b], [c, d]]).I\n",
    "\n",
    "    [[a, b], [c, d]] = [[(a*b+1),-a],[-b,1]]\n",
    "    return arnold(img, [N, a, b, c, d])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "acb1da0f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv1.weight      torch.Size([64, 3, 7, 7])\n",
      "bn1.weight      torch.Size([64])\n",
      "bn1.bias      torch.Size([64])\n",
      "layer1.0.conv1.weight      torch.Size([64, 64, 3, 3])\n",
      "layer1.0.bn1.weight      torch.Size([64])\n",
      "layer1.0.bn1.bias      torch.Size([64])\n",
      "layer1.0.conv2.weight      torch.Size([64, 64, 3, 3])\n",
      "layer1.0.bn2.weight      torch.Size([64])\n",
      "layer1.0.bn2.bias      torch.Size([64])\n",
      "layer1.1.conv1.weight      torch.Size([64, 64, 3, 3])\n",
      "layer1.1.bn1.weight      torch.Size([64])\n",
      "layer1.1.bn1.bias      torch.Size([64])\n",
      "layer1.1.conv2.weight      torch.Size([64, 64, 3, 3])\n",
      "layer1.1.bn2.weight      torch.Size([64])\n",
      "layer1.1.bn2.bias      torch.Size([64])\n",
      "layer2.0.conv1.weight      torch.Size([128, 64, 3, 3])\n",
      "layer2.0.bn1.weight      torch.Size([128])\n",
      "layer2.0.bn1.bias      torch.Size([128])\n",
      "layer2.0.conv2.weight      torch.Size([128, 128, 3, 3])\n",
      "layer2.0.bn2.weight      torch.Size([128])\n",
      "layer2.0.bn2.bias      torch.Size([128])\n",
      "layer2.0.downsample.0.weight      torch.Size([128, 64, 1, 1])\n",
      "layer2.0.downsample.1.weight      torch.Size([128])\n",
      "layer2.0.downsample.1.bias      torch.Size([128])\n",
      "layer2.1.conv1.weight      torch.Size([128, 128, 3, 3])\n",
      "layer2.1.bn1.weight      torch.Size([128])\n",
      "layer2.1.bn1.bias      torch.Size([128])\n",
      "layer2.1.conv2.weight      torch.Size([128, 128, 3, 3])\n",
      "layer2.1.bn2.weight      torch.Size([128])\n",
      "layer2.1.bn2.bias      torch.Size([128])\n",
      "layer3.0.conv1.weight      torch.Size([256, 128, 3, 3])\n",
      "layer3.0.bn1.weight      torch.Size([256])\n",
      "layer3.0.bn1.bias      torch.Size([256])\n",
      "layer3.0.conv2.weight      torch.Size([256, 256, 3, 3])\n",
      "layer3.0.bn2.weight      torch.Size([256])\n",
      "layer3.0.bn2.bias      torch.Size([256])\n",
      "layer3.0.downsample.0.weight      torch.Size([256, 128, 1, 1])\n",
      "layer3.0.downsample.1.weight      torch.Size([256])\n",
      "layer3.0.downsample.1.bias      torch.Size([256])\n",
      "layer3.1.conv1.weight      torch.Size([256, 256, 3, 3])\n",
      "layer3.1.bn1.weight      torch.Size([256])\n",
      "layer3.1.bn1.bias      torch.Size([256])\n",
      "layer3.1.conv2.weight      torch.Size([256, 256, 3, 3])\n",
      "layer3.1.bn2.weight      torch.Size([256])\n",
      "layer3.1.bn2.bias      torch.Size([256])\n",
      "layer4.0.conv1.weight      torch.Size([512, 256, 3, 3])\n",
      "layer4.0.bn1.weight      torch.Size([512])\n",
      "layer4.0.bn1.bias      torch.Size([512])\n",
      "layer4.0.conv2.weight      torch.Size([512, 512, 3, 3])\n",
      "layer4.0.bn2.weight      torch.Size([512])\n",
      "layer4.0.bn2.bias      torch.Size([512])\n",
      "layer4.0.downsample.0.weight      torch.Size([512, 256, 1, 1])\n",
      "layer4.0.downsample.1.weight      torch.Size([512])\n",
      "layer4.0.downsample.1.bias      torch.Size([512])\n",
      "layer4.1.conv1.weight      torch.Size([512, 512, 3, 3])\n",
      "layer4.1.bn1.weight      torch.Size([512])\n",
      "layer4.1.bn1.bias      torch.Size([512])\n",
      "layer4.1.conv2.weight      torch.Size([512, 512, 3, 3])\n",
      "layer4.1.bn2.weight      torch.Size([512])\n",
      "layer4.1.bn2.bias      torch.Size([512])\n",
      "fc.weight      torch.Size([1000, 512])\n",
      "fc.bias      torch.Size([1000])\n",
      "Test: [  0/196]\tTime  6.814 ( 6.814)\tLoss 6.7443e-01 (6.7443e-01)\tAcc@1  80.08 ( 80.08)\tAcc@5  96.09 ( 96.09)\n",
      "Test: [ 10/196]\tTime  0.183 ( 1.007)\tLoss 1.1975e+00 (8.8222e-01)\tAcc@1  67.97 ( 77.59)\tAcc@5  90.23 ( 92.90)\n",
      "Test: [ 20/196]\tTime  0.054 ( 0.952)\tLoss 8.8966e-01 (9.0779e-01)\tAcc@1  80.47 ( 76.86)\tAcc@5  91.02 ( 92.62)\n",
      "Test: [ 30/196]\tTime  1.542 ( 0.995)\tLoss 9.2779e-01 (8.7068e-01)\tAcc@1  77.34 ( 77.92)\tAcc@5  92.97 ( 92.87)\n",
      "Test: [ 40/196]\tTime  0.054 ( 0.947)\tLoss 8.8652e-01 (9.1349e-01)\tAcc@1  75.39 ( 76.23)\tAcc@5  95.70 ( 93.04)\n",
      "Test: [ 50/196]\tTime  3.142 ( 0.957)\tLoss 6.2451e-01 (9.0812e-01)\tAcc@1  83.98 ( 75.98)\tAcc@5  95.70 ( 93.28)\n",
      "Test: [ 60/196]\tTime  0.069 ( 0.927)\tLoss 1.1483e+00 (9.2004e-01)\tAcc@1  71.88 ( 75.67)\tAcc@5  94.14 ( 93.41)\n",
      "Test: [ 70/196]\tTime  0.249 ( 0.951)\tLoss 8.1401e-01 (9.0265e-01)\tAcc@1  79.30 ( 76.28)\tAcc@5  94.14 ( 93.56)\n",
      "Test: [ 80/196]\tTime  0.063 ( 0.956)\tLoss 1.5958e+00 (9.2379e-01)\tAcc@1  64.45 ( 76.02)\tAcc@5  85.55 ( 93.28)\n",
      "Test: [ 90/196]\tTime  0.054 ( 0.992)\tLoss 2.2526e+00 (9.9031e-01)\tAcc@1  49.22 ( 74.71)\tAcc@5  79.69 ( 92.45)\n",
      "Test: [100/196]\tTime  0.118 ( 0.977)\tLoss 1.6806e+00 (1.0526e+00)\tAcc@1  57.03 ( 73.44)\tAcc@5  84.77 ( 91.65)\n",
      "Test: [110/196]\tTime  1.013 ( 0.998)\tLoss 1.1637e+00 (1.0807e+00)\tAcc@1  71.88 ( 72.94)\tAcc@5  89.84 ( 91.25)\n",
      "Test: [120/196]\tTime  0.054 ( 0.989)\tLoss 1.8209e+00 (1.1061e+00)\tAcc@1  58.59 ( 72.57)\tAcc@5  79.30 ( 90.83)\n",
      "Test: [130/196]\tTime  3.986 ( 1.006)\tLoss 9.3011e-01 (1.1458e+00)\tAcc@1  76.56 ( 71.68)\tAcc@5  94.14 ( 90.39)\n",
      "Test: [140/196]\tTime  0.057 ( 0.994)\tLoss 1.3774e+00 (1.1680e+00)\tAcc@1  65.23 ( 71.27)\tAcc@5  85.94 ( 90.13)\n",
      "Test: [150/196]\tTime  1.976 ( 0.999)\tLoss 1.3499e+00 (1.1946e+00)\tAcc@1  73.44 ( 70.79)\tAcc@5  85.94 ( 89.73)\n",
      "Test: [160/196]\tTime  0.118 ( 1.021)\tLoss 1.0732e+00 (1.2141e+00)\tAcc@1  76.95 ( 70.48)\tAcc@5  90.62 ( 89.49)\n",
      "Test: [170/196]\tTime  0.053 ( 1.021)\tLoss 8.9346e-01 (1.2377e+00)\tAcc@1  77.34 ( 69.97)\tAcc@5  91.41 ( 89.16)\n",
      "Test: [180/196]\tTime  0.084 ( 1.042)\tLoss 1.4580e+00 (1.2560e+00)\tAcc@1  62.11 ( 69.62)\tAcc@5  89.45 ( 88.94)\n",
      "Test: [190/196]\tTime  0.118 ( 1.040)\tLoss 1.3996e+00 (1.2547e+00)\tAcc@1  63.28 ( 69.58)\tAcc@5  91.80 ( 88.99)\n",
      " * Acc@1 69.758 Acc@5 89.076\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(69.7580, device='cuda:0')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torchvision.models as models\n",
    "cudnn.benchmark = True\n",
    "criterion = nn.CrossEntropyLoss().cuda()\n",
    "\n",
    "# change this model\n",
    "# model = models.googlenet(pretrained=True)\n",
    "#model = models.resnet101(pretrained=True)\n",
    "#model = models.mobilenet_v2(pretrained=True)\n",
    "#model = models.densenet121(pretrained=True)\n",
    "model = models.resnet18(pretrained=True)\n",
    "#model = models.vgg16(pretrained=True)\n",
    "model = model.cuda()\n",
    "\n",
    "# name for each layer\n",
    "for name, param in model.named_parameters():\n",
    "    print(name,'    ', param.size())\n",
    "\n",
    "\n",
    "\n",
    "# the original accuracy\n",
    "validate(val_loader, model, criterion) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36f75640",
   "metadata": {},
   "source": [
    "## Encryption"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "157156ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer half weights size is:  torch.Size([3, 3, 7, 7])\n",
      "need 0.000137 sec\n",
      "Test: [  0/196]\tTime  3.725 ( 3.725)\tLoss 6.7134e-01 (6.7134e-01)\tAcc@1  82.81 ( 82.81)\tAcc@5  96.88 ( 96.88)\n",
      "Test: [ 10/196]\tTime  0.597 ( 0.876)\tLoss 1.2217e+00 (9.0819e-01)\tAcc@1  67.19 ( 77.31)\tAcc@5  90.23 ( 92.65)\n",
      "Test: [ 20/196]\tTime  1.999 ( 0.870)\tLoss 9.2844e-01 (9.3043e-01)\tAcc@1  78.52 ( 76.38)\tAcc@5  90.62 ( 92.52)\n",
      "Test: [ 30/196]\tTime  1.404 ( 0.830)\tLoss 9.3338e-01 (8.9457e-01)\tAcc@1  77.34 ( 77.36)\tAcc@5  92.97 ( 92.74)\n",
      "Test: [ 40/196]\tTime  0.053 ( 0.778)\tLoss 8.9877e-01 (9.3504e-01)\tAcc@1  75.78 ( 75.75)\tAcc@5  95.70 ( 92.93)\n",
      "Test: [ 50/196]\tTime  3.497 ( 0.856)\tLoss 6.0718e-01 (9.2807e-01)\tAcc@1  85.16 ( 75.61)\tAcc@5  96.88 ( 93.24)\n",
      "Test: [ 60/196]\tTime  0.054 ( 0.867)\tLoss 1.1745e+00 (9.3949e-01)\tAcc@1  71.48 ( 75.34)\tAcc@5  92.97 ( 93.33)\n",
      "Test: [ 70/196]\tTime  3.743 ( 0.907)\tLoss 7.9589e-01 (9.2197e-01)\tAcc@1  78.91 ( 75.86)\tAcc@5  94.53 ( 93.43)\n",
      "Test: [ 80/196]\tTime  0.067 ( 0.879)\tLoss 1.6319e+00 (9.4208e-01)\tAcc@1  63.67 ( 75.67)\tAcc@5  85.55 ( 93.13)\n",
      "Test: [ 90/196]\tTime  2.685 ( 0.886)\tLoss 2.2929e+00 (1.0102e+00)\tAcc@1  48.05 ( 74.32)\tAcc@5  78.91 ( 92.28)\n",
      "Test: [100/196]\tTime  0.093 ( 0.863)\tLoss 1.7247e+00 (1.0735e+00)\tAcc@1  56.25 ( 73.02)\tAcc@5  84.77 ( 91.44)\n",
      "Test: [110/196]\tTime  3.712 ( 0.880)\tLoss 1.1205e+00 (1.1009e+00)\tAcc@1  75.00 ( 72.52)\tAcc@5  91.02 ( 91.04)\n",
      "Test: [120/196]\tTime  1.280 ( 0.866)\tLoss 1.8196e+00 (1.1268e+00)\tAcc@1  58.59 ( 72.13)\tAcc@5  78.91 ( 90.59)\n",
      "Test: [130/196]\tTime  2.207 ( 0.861)\tLoss 9.5574e-01 (1.1667e+00)\tAcc@1  74.61 ( 71.25)\tAcc@5  92.97 ( 90.14)\n",
      "Test: [140/196]\tTime  2.037 ( 0.861)\tLoss 1.4181e+00 (1.1892e+00)\tAcc@1  63.67 ( 70.80)\tAcc@5  85.94 ( 89.89)\n",
      "Test: [150/196]\tTime  0.054 ( 0.863)\tLoss 1.3649e+00 (1.2163e+00)\tAcc@1  72.66 ( 70.29)\tAcc@5  85.16 ( 89.46)\n",
      "Test: [160/196]\tTime  3.801 ( 0.890)\tLoss 1.1062e+00 (1.2356e+00)\tAcc@1  77.34 ( 69.98)\tAcc@5  90.23 ( 89.21)\n",
      "Test: [170/196]\tTime  0.053 ( 0.889)\tLoss 9.3054e-01 (1.2590e+00)\tAcc@1  75.39 ( 69.48)\tAcc@5  91.80 ( 88.88)\n",
      "Test: [180/196]\tTime  3.547 ( 0.910)\tLoss 1.4594e+00 (1.2773e+00)\tAcc@1  60.94 ( 69.13)\tAcc@5  89.84 ( 88.67)\n",
      "Test: [190/196]\tTime  0.053 ( 0.902)\tLoss 1.4218e+00 (1.2758e+00)\tAcc@1  63.67 ( 69.12)\tAcc@5  91.41 ( 88.72)\n",
      " * Acc@1 69.284 Acc@5 88.804\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(69.2840, device='cuda:0')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import time \n",
    "import numpy as np\n",
    "\n",
    "#layer 1\n",
    "weight = model.conv1.weight\n",
    "weight_half = weight[:3,:3]\n",
    "print('layer half weights size is: ',weight_half.size())\n",
    "weight_numpy = weight_half.detach().cpu().numpy()\n",
    "start = time.time()\n",
    "arn_weight = arnold(weight_numpy,[1, 1,1,1,2])\n",
    "end = time.time()\n",
    "total = end - start\n",
    "# print('the difference is',np.count_nonzero(weight_numpy-arn_weight))\n",
    "print('need {:.6f} sec'.format(total))\n",
    "\n",
    "model.conv1.weight.data[:3,:3] = torch.from_numpy(arn_weight).cuda()\n",
    "#model.layer3[0].conv2.weight.data[:192,:192] = torch.from_numpy(arn_weight).cuda()\n",
    "#model.conv2.conv.weight.data[:32,:32] = torch.from_numpy(arn_weight).cuda()\n",
    "validate(val_loader, model, criterion) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d0edbe0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer half weights size is:  torch.Size([64, 64, 3, 3])\n",
      "need 0.005261 sec\n",
      "Test: [  0/196]\tTime  3.464 ( 3.464)\tLoss 9.7483e+00 (9.7483e+00)\tAcc@1   0.00 (  0.00)\tAcc@5   0.39 (  0.39)\n",
      "Test: [ 10/196]\tTime  0.795 ( 0.942)\tLoss 9.9751e+00 (1.0968e+01)\tAcc@1   0.00 (  0.00)\tAcc@5   0.00 (  0.21)\n",
      "Test: [ 20/196]\tTime  0.354 ( 0.887)\tLoss 9.7799e+00 (1.0833e+01)\tAcc@1   0.00 (  0.00)\tAcc@5   0.00 (  0.13)\n",
      "Test: [ 30/196]\tTime  3.242 ( 0.980)\tLoss 1.1808e+01 (1.0787e+01)\tAcc@1   0.00 (  0.49)\tAcc@5   0.00 (  0.98)\n",
      "Test: [ 40/196]\tTime  0.053 ( 0.920)\tLoss 9.8546e+00 (1.0696e+01)\tAcc@1   0.00 (  0.37)\tAcc@5   0.00 (  0.74)\n",
      "Test: [ 50/196]\tTime  4.102 ( 0.922)\tLoss 1.0644e+01 (1.0669e+01)\tAcc@1   0.00 (  0.30)\tAcc@5   0.00 (  0.60)\n",
      "Test: [ 60/196]\tTime  0.057 ( 0.895)\tLoss 9.5025e+00 (1.0521e+01)\tAcc@1   0.00 (  0.25)\tAcc@5   0.00 (  0.50)\n",
      "Test: [ 70/196]\tTime  3.165 ( 0.922)\tLoss 9.5753e+00 (1.0527e+01)\tAcc@1   0.00 (  0.21)\tAcc@5   0.00 (  0.43)\n",
      "Test: [ 80/196]\tTime  0.115 ( 0.917)\tLoss 9.8693e+00 (1.0434e+01)\tAcc@1   0.00 (  0.22)\tAcc@5   0.00 (  0.56)\n",
      "Test: [ 90/196]\tTime  3.617 ( 0.938)\tLoss 8.2491e+00 (1.0337e+01)\tAcc@1   0.00 (  0.20)\tAcc@5   0.00 (  0.50)\n",
      "Test: [100/196]\tTime  0.053 ( 0.935)\tLoss 8.1790e+00 (1.0208e+01)\tAcc@1   0.00 (  0.18)\tAcc@5   0.00 (  0.50)\n",
      "Test: [110/196]\tTime  3.463 ( 0.954)\tLoss 9.6956e+00 (1.0117e+01)\tAcc@1   0.39 (  0.17)\tAcc@5   1.95 (  0.52)\n",
      "Test: [120/196]\tTime  0.054 ( 0.941)\tLoss 8.5667e+00 (1.0034e+01)\tAcc@1   0.00 (  0.19)\tAcc@5   0.00 (  0.57)\n",
      "Test: [130/196]\tTime  3.547 ( 0.959)\tLoss 9.1579e+00 (9.9623e+00)\tAcc@1   0.00 (  0.22)\tAcc@5   0.39 (  0.68)\n",
      "Test: [140/196]\tTime  0.054 ( 0.942)\tLoss 1.0004e+01 (9.8865e+00)\tAcc@1   0.00 (  0.23)\tAcc@5   0.00 (  0.72)\n",
      "Test: [150/196]\tTime  3.408 ( 0.941)\tLoss 8.9827e+00 (9.8270e+00)\tAcc@1   0.00 (  0.22)\tAcc@5   0.78 (  0.69)\n",
      "Test: [160/196]\tTime  0.097 ( 0.929)\tLoss 9.3536e+00 (9.7930e+00)\tAcc@1   0.00 (  0.21)\tAcc@5   0.00 (  0.72)\n",
      "Test: [170/196]\tTime  2.783 ( 0.930)\tLoss 1.0220e+01 (9.7428e+00)\tAcc@1   0.00 (  0.20)\tAcc@5   0.00 (  0.74)\n",
      "Test: [180/196]\tTime  0.124 ( 0.915)\tLoss 8.6435e+00 (9.6869e+00)\tAcc@1   0.00 (  0.23)\tAcc@5   0.00 (  0.79)\n",
      "Test: [190/196]\tTime  2.206 ( 0.913)\tLoss 9.3875e+00 (9.6664e+00)\tAcc@1   0.00 (  0.22)\tAcc@5   0.00 (  0.76)\n",
      " * Acc@1 0.216 Acc@5 0.764\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(0.2160, device='cuda:0')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "import time \n",
    "import numpy as np\n",
    "\n",
    "model = models.resnet18(pretrained=True)\n",
    "model = model.cuda()\n",
    "\n",
    "\n",
    "#layer 2\n",
    "weight = model.layer1[0].conv1.weight\n",
    "weight_half = weight[:64,:64]\n",
    "print('layer half weights size is: ',weight_half.size())\n",
    "weight_numpy = weight_half.detach().cpu().numpy()\n",
    "start = time.time()\n",
    "arn_weight = arnold(weight_numpy,[1, 1,1,1,2])\n",
    "end = time.time()\n",
    "total = end - start\n",
    "# print('the difference is',np.count_nonzero(weight_numpy-arn_weight))\n",
    "print('need {:.6f} sec'.format(total))\n",
    "\n",
    "model.layer1[0].conv1.weight.data[:64,:64] = torch.from_numpy(arn_weight).cuda()\n",
    "#model.layer3[0].conv2.weight.data[:192,:192] = torch.from_numpy(arn_weight).cuda()\n",
    "#model.conv2.conv.weight.data[:32,:32] = torch.from_numpy(arn_weight).cuda()\n",
    "validate(val_loader, model, criterion) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba0ee720",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer half weights size is:  torch.Size([64, 64, 3, 3])\n",
      "need 0.004942 sec\n",
      "Test: [  0/196]\tTime  4.175 ( 4.175)\tLoss 6.5223e+00 (6.5223e+00)\tAcc@1   3.52 (  3.52)\tAcc@5  19.14 ( 19.14)\n",
      "Test: [ 10/196]\tTime  0.098 ( 1.044)\tLoss 9.1497e+00 (1.0493e+01)\tAcc@1   7.42 (  3.69)\tAcc@5  22.66 ( 12.61)\n",
      "Test: [ 20/196]\tTime  1.206 ( 0.878)\tLoss 1.6068e+01 (1.1047e+01)\tAcc@1   0.39 (  2.90)\tAcc@5   2.34 ( 10.42)\n",
      "Test: [ 30/196]\tTime  0.054 ( 0.834)\tLoss 1.3400e+01 (1.1572e+01)\tAcc@1   0.00 (  2.18)\tAcc@5   0.78 (  8.03)\n",
      "Test: [ 40/196]\tTime  1.011 ( 0.825)\tLoss 1.6469e+01 (1.2348e+01)\tAcc@1   0.00 (  1.65)\tAcc@5   0.00 (  6.11)\n",
      "Test: [ 50/196]\tTime  0.053 ( 0.836)\tLoss 1.5083e+01 (1.2917e+01)\tAcc@1   0.00 (  1.33)\tAcc@5   0.00 (  4.92)\n",
      "Test: [ 60/196]\tTime  0.054 ( 0.822)\tLoss 1.0111e+01 (1.3256e+01)\tAcc@1   0.00 (  1.11)\tAcc@5   3.12 (  4.24)\n",
      "Test: [ 70/196]\tTime  0.056 ( 0.843)\tLoss 1.4570e+01 (1.3387e+01)\tAcc@1   1.17 (  1.12)\tAcc@5   2.34 (  4.20)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import time \n",
    "import numpy as np\n",
    "\n",
    "model = models.resnet18(pretrained=True)\n",
    "model = model.cuda()\n",
    "\n",
    "\n",
    "#layer 3\n",
    "weight = model.layer1[0].conv2.weight\n",
    "weight_half = weight[:64,:64]\n",
    "print('layer half weights size is: ',weight_half.size())\n",
    "weight_numpy = weight_half.detach().cpu().numpy()\n",
    "start = time.time()\n",
    "arn_weight = arnold(weight_numpy,[1, 1,1,1,2])\n",
    "end = time.time()\n",
    "total = end - start\n",
    "# print('the difference is',np.count_nonzero(weight_numpy-arn_weight))\n",
    "print('need {:.6f} sec'.format(total))\n",
    "\n",
    "model.layer1[0].conv2.weight.data[:64,:64] = torch.from_numpy(arn_weight).cuda()\n",
    "#model.layer3[0].conv2.weight.data[:192,:192] = torch.from_numpy(arn_weight).cuda()\n",
    "#model.conv2.conv.weight.data[:32,:32] = torch.from_numpy(arn_weight).cuda()\n",
    "validate(val_loader, model, criterion) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aab1fd03",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time \n",
    "import numpy as np\n",
    "\n",
    "model = models.resnet18(pretrained=True)\n",
    "model = model.cuda()\n",
    "\n",
    "\n",
    "#layer 4\n",
    "weight = model.layer1[1].conv1.weight\n",
    "weight_half = weight[:64,:64]\n",
    "print('layer half weights size is: ',weight_half.size())\n",
    "weight_numpy = weight_half.detach().cpu().numpy()\n",
    "start = time.time()\n",
    "arn_weight = arnold(weight_numpy,[1, 1,1,1,2])\n",
    "end = time.time()\n",
    "total = end - start\n",
    "# print('the difference is',np.count_nonzero(weight_numpy-arn_weight))\n",
    "print('need {:.6f} sec'.format(total))\n",
    "\n",
    "model.layer1[1].conv1.weight.data[:64,:64] = torch.from_numpy(arn_weight).cuda()\n",
    "#model.layer3[0].conv2.weight.data[:192,:192] = torch.from_numpy(arn_weight).cuda()\n",
    "#model.conv2.conv.weight.data[:32,:32] = torch.from_numpy(arn_weight).cuda()\n",
    "validate(val_loader, model, criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fb4cc3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time \n",
    "import numpy as np\n",
    "\n",
    "model = models.resnet18(pretrained=True)\n",
    "model = model.cuda()\n",
    "\n",
    "\n",
    "#layer 5\n",
    "weight = model.layer1[1].conv2.weight\n",
    "weight_half = weight[:64,:64]\n",
    "print('layer half weights size is: ',weight_half.size())\n",
    "weight_numpy = weight_half.detach().cpu().numpy()\n",
    "start = time.time()\n",
    "arn_weight = arnold(weight_numpy,[1, 1,1,1,2])\n",
    "end = time.time()\n",
    "total = end - start\n",
    "# print('the difference is',np.count_nonzero(weight_numpy-arn_weight))\n",
    "print('need {:.6f} sec'.format(total))\n",
    "\n",
    "model.layer1[1].conv2.weight.data[:64,:64] = torch.from_numpy(arn_weight).cuda()\n",
    "#model.layer3[0].conv2.weight.data[:192,:192] = torch.from_numpy(arn_weight).cuda()\n",
    "#model.conv2.conv.weight.data[:32,:32] = torch.from_numpy(arn_weight).cuda()\n",
    "validate(val_loader, model, criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8784c49e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#layer2.0.conv1.weight\n",
    "\n",
    "import time \n",
    "import numpy as np\n",
    "\n",
    "model = models.resnet18(pretrained=True)\n",
    "model = model.cuda()\n",
    "\n",
    "\n",
    "#layer 6\n",
    "weight = model.layer2[0].conv1.weight\n",
    "weight_half = weight[:64,:64]\n",
    "print('layer half weights size is: ',weight_half.size())\n",
    "weight_numpy = weight_half.detach().cpu().numpy()\n",
    "start = time.time()\n",
    "arn_weight = arnold(weight_numpy,[1, 1,1,1,2])\n",
    "end = time.time()\n",
    "total = end - start\n",
    "# print('the difference is',np.count_nonzero(weight_numpy-arn_weight))\n",
    "print('need {:.6f} sec'.format(total))\n",
    "\n",
    "model.layer2[0].conv1.weight.data[:64,:64] = torch.from_numpy(arn_weight).cuda()\n",
    "#model.layer3[0].conv2.weight.data[:192,:192] = torch.from_numpy(arn_weight).cuda()\n",
    "#model.conv2.conv.weight.data[:32,:32] = torch.from_numpy(arn_weight).cuda()\n",
    "validate(val_loader, model, criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dd5280e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#layer2.0.conv2.weight\n",
    "\n",
    "import time \n",
    "import numpy as np\n",
    "\n",
    "model = models.resnet18(pretrained=True)\n",
    "model = model.cuda()\n",
    "\n",
    "\n",
    "#layer 7\n",
    "weight = model.layer2[0].conv2.weight\n",
    "weight_half = weight[:128,:128]\n",
    "print('layer half weights size is: ',weight_half.size())\n",
    "weight_numpy = weight_half.detach().cpu().numpy()\n",
    "start = time.time()\n",
    "arn_weight = arnold(weight_numpy,[1, 1,1,1,2])\n",
    "end = time.time()\n",
    "total = end - start\n",
    "# print('the difference is',np.count_nonzero(weight_numpy-arn_weight))\n",
    "print('need {:.6f} sec'.format(total))\n",
    "\n",
    "model.layer2[0].conv2.weight.data[:128,:128] = torch.from_numpy(arn_weight).cuda()\n",
    "#model.layer3[0].conv2.weight.data[:192,:192] = torch.from_numpy(arn_weight).cuda()\n",
    "#model.conv2.conv.weight.data[:32,:32] = torch.from_numpy(arn_weight).cuda()\n",
    "validate(val_loader, model, criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65f624b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#layer2.1.conv1.weight\n",
    "\n",
    "import time \n",
    "import numpy as np\n",
    "\n",
    "model = models.resnet18(pretrained=True)\n",
    "model = model.cuda()\n",
    "\n",
    "\n",
    "#layer 8\n",
    "weight = model.layer2[1].conv1.weight\n",
    "weight_half = weight[:128,:128]\n",
    "print('layer half weights size is: ',weight_half.size())\n",
    "weight_numpy = weight_half.detach().cpu().numpy()\n",
    "start = time.time()\n",
    "arn_weight = arnold(weight_numpy,[1, 1,1,1,2])\n",
    "end = time.time()\n",
    "total = end - start\n",
    "# print('the difference is',np.count_nonzero(weight_numpy-arn_weight))\n",
    "print('need {:.6f} sec'.format(total))\n",
    "\n",
    "model.layer2[1].conv1.weight.data[:128,:128] = torch.from_numpy(arn_weight).cuda()\n",
    "#model.layer3[0].conv2.weight.data[:192,:192] = torch.from_numpy(arn_weight).cuda()\n",
    "#model.conv2.conv.weight.data[:32,:32] = torch.from_numpy(arn_weight).cuda()\n",
    "validate(val_loader, model, criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbf3c2ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import time \n",
    "import numpy as np\n",
    "\n",
    "model = models.resnet18(pretrained=True)\n",
    "model = model.cuda()\n",
    "\n",
    "\n",
    "#layer 9\n",
    "weight = model.layer2[1].conv2.weight\n",
    "weight_half = weight[:128,:128]\n",
    "print('layer half weights size is: ',weight_half.size())\n",
    "weight_numpy = weight_half.detach().cpu().numpy()\n",
    "start = time.time()\n",
    "arn_weight = arnold(weight_numpy,[1, 1,1,1,2])\n",
    "end = time.time()\n",
    "total = end - start\n",
    "# print('the difference is',np.count_nonzero(weight_numpy-arn_weight))\n",
    "print('need {:.6f} sec'.format(total))\n",
    "\n",
    "model.layer2[1].conv2.weight.data[:128,:128] = torch.from_numpy(arn_weight).cuda()\n",
    "#model.layer3[0].conv2.weight.data[:192,:192] = torch.from_numpy(arn_weight).cuda()\n",
    "#model.conv2.conv.weight.data[:32,:32] = torch.from_numpy(arn_weight).cuda()\n",
    "validate(val_loader, model, criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ce564b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import time \n",
    "import numpy as np\n",
    "\n",
    "model = models.resnet18(pretrained=True)\n",
    "model = model.cuda()\n",
    "\n",
    "\n",
    "#layer 10\n",
    "weight = model.layer3[0].conv1.weight\n",
    "weight_half = weight[:128,:128]\n",
    "print('layer half weights size is: ',weight_half.size())\n",
    "weight_numpy = weight_half.detach().cpu().numpy()\n",
    "start = time.time()\n",
    "arn_weight = arnold(weight_numpy,[1, 1,1,1,2])\n",
    "end = time.time()\n",
    "total = end - start\n",
    "# print('the difference is',np.count_nonzero(weight_numpy-arn_weight))\n",
    "print('need {:.6f} sec'.format(total))\n",
    "\n",
    "model.layer3[0].conv1.weight.data[:128,:128] = torch.from_numpy(arn_weight).cuda()\n",
    "#model.layer3[0].conv2.weight.data[:192,:192] = torch.from_numpy(arn_weight).cuda()\n",
    "#model.conv2.conv.weight.data[:32,:32] = torch.from_numpy(arn_weight).cuda()\n",
    "validate(val_loader, model, criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61c40f24",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time \n",
    "import numpy as np\n",
    "\n",
    "model = models.resnet18(pretrained=True)\n",
    "model = model.cuda()\n",
    "\n",
    "\n",
    "#layer 11\n",
    "weight = model.layer3[0].conv2.weight\n",
    "weight_half = weight[:256,:256]\n",
    "print('layer half weights size is: ',weight_half.size())\n",
    "weight_numpy = weight_half.detach().cpu().numpy()\n",
    "start = time.time()\n",
    "arn_weight = arnold(weight_numpy,[1, 1,1,1,2])\n",
    "end = time.time()\n",
    "total = end - start\n",
    "# print('the difference is',np.count_nonzero(weight_numpy-arn_weight))\n",
    "print('need {:.6f} sec'.format(total))\n",
    "\n",
    "model.layer3[0].conv2.weight.data[:256,:256] = torch.from_numpy(arn_weight).cuda()\n",
    "#model.layer3[0].conv2.weight.data[:192,:192] = torch.from_numpy(arn_weight).cuda()\n",
    "#model.conv2.conv.weight.data[:32,:32] = torch.from_numpy(arn_weight).cuda()\n",
    "validate(val_loader, model, criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec7db9be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time \n",
    "import numpy as np\n",
    "\n",
    "model = models.resnet18(pretrained=True)\n",
    "model = model.cuda()\n",
    "\n",
    "\n",
    "#layer 12\n",
    "weight = model.layer3[1].conv1.weight\n",
    "weight_half = weight[:256,:256]\n",
    "print('layer half weights size is: ',weight_half.size())\n",
    "weight_numpy = weight_half.detach().cpu().numpy()\n",
    "start = time.time()\n",
    "arn_weight = arnold(weight_numpy,[1, 1,1,1,2])\n",
    "end = time.time()\n",
    "total = end - start\n",
    "# print('the difference is',np.count_nonzero(weight_numpy-arn_weight))\n",
    "print('need {:.6f} sec'.format(total))\n",
    "\n",
    "model.layer3[1].conv1.weight.data[:256,:256] = torch.from_numpy(arn_weight).cuda()\n",
    "#model.layer3[0].conv2.weight.data[:192,:192] = torch.from_numpy(arn_weight).cuda()\n",
    "#model.conv2.conv.weight.data[:32,:32] = torch.from_numpy(arn_weight).cuda()\n",
    "validate(val_loader, model, criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1beb9c2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time \n",
    "import numpy as np\n",
    "\n",
    "model = models.resnet18(pretrained=True)\n",
    "model = model.cuda()\n",
    "\n",
    "\n",
    "#layer 13\n",
    "weight = model.layer3[1].conv2.weight\n",
    "weight_half = weight[:256,:256]\n",
    "print('layer half weights size is: ',weight_half.size())\n",
    "weight_numpy = weight_half.detach().cpu().numpy()\n",
    "start = time.time()\n",
    "arn_weight = arnold(weight_numpy,[1, 1,1,1,2])\n",
    "end = time.time()\n",
    "total = end - start\n",
    "# print('the difference is',np.count_nonzero(weight_numpy-arn_weight))\n",
    "print('need {:.6f} sec'.format(total))\n",
    "\n",
    "model.layer3[1].conv2.weight.data[:256,:256] = torch.from_numpy(arn_weight).cuda()\n",
    "#model.layer3[0].conv2.weight.data[:192,:192] = torch.from_numpy(arn_weight).cuda()\n",
    "#model.conv2.conv.weight.data[:32,:32] = torch.from_numpy(arn_weight).cuda()\n",
    "validate(val_loader, model, criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9437ee06",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time \n",
    "import numpy as np\n",
    "\n",
    "model = models.resnet18(pretrained=True)\n",
    "model = model.cuda()\n",
    "\n",
    "\n",
    "#layer 14\n",
    "weight = model.layer4[0].conv1.weight\n",
    "weight_half = weight[:256,:256]\n",
    "print('layer half weights size is: ',weight_half.size())\n",
    "weight_numpy = weight_half.detach().cpu().numpy()\n",
    "start = time.time()\n",
    "arn_weight = arnold(weight_numpy,[1, 1,1,1,2])\n",
    "end = time.time()\n",
    "total = end - start\n",
    "# print('the difference is',np.count_nonzero(weight_numpy-arn_weight))\n",
    "print('need {:.6f} sec'.format(total))\n",
    "\n",
    "model.layer4[0].conv1.weight.data[:256,:256] = torch.from_numpy(arn_weight).cuda()\n",
    "#model.layer3[0].conv2.weight.data[:192,:192] = torch.from_numpy(arn_weight).cuda()\n",
    "#model.conv2.conv.weight.data[:32,:32] = torch.from_numpy(arn_weight).cuda()\n",
    "validate(val_loader, model, criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a92fdbd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time \n",
    "import numpy as np\n",
    "\n",
    "model = models.resnet18(pretrained=True)\n",
    "model = model.cuda()\n",
    "\n",
    "\n",
    "#layer 15\n",
    "weight = model.layer4[0].conv2.weight\n",
    "weight_half = weight[:512,:512]\n",
    "print('layer half weights size is: ',weight_half.size())\n",
    "weight_numpy = weight_half.detach().cpu().numpy()\n",
    "start = time.time()\n",
    "arn_weight = arnold(weight_numpy,[1, 1,1,1,2])\n",
    "end = time.time()\n",
    "total = end - start\n",
    "# print('the difference is',np.count_nonzero(weight_numpy-arn_weight))\n",
    "print('need {:.6f} sec'.format(total))\n",
    "\n",
    "model.layer4[0].conv2.weight.data[:512,:512] = torch.from_numpy(arn_weight).cuda()\n",
    "#model.layer3[0].conv2.weight.data[:192,:192] = torch.from_numpy(arn_weight).cuda()\n",
    "#model.conv2.conv.weight.data[:32,:32] = torch.from_numpy(arn_weight).cuda()\n",
    "validate(val_loader, model, criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8f936b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time \n",
    "import numpy as np\n",
    "\n",
    "model = models.resnet18(pretrained=True)\n",
    "model = model.cuda()\n",
    "\n",
    "\n",
    "#layer 16\n",
    "weight = model.layer4[1].conv1.weight\n",
    "weight_half = weight[:512,:512]\n",
    "print('layer half weights size is: ',weight_half.size())\n",
    "weight_numpy = weight_half.detach().cpu().numpy()\n",
    "start = time.time()\n",
    "arn_weight = arnold(weight_numpy,[1, 1,1,1,2])\n",
    "end = time.time()\n",
    "total = end - start\n",
    "# print('the difference is',np.count_nonzero(weight_numpy-arn_weight))\n",
    "print('need {:.6f} sec'.format(total))\n",
    "\n",
    "model.layer4[1].conv1.weight.data[:512,:512] = torch.from_numpy(arn_weight).cuda()\n",
    "#model.layer3[0].conv2.weight.data[:192,:192] = torch.from_numpy(arn_weight).cuda()\n",
    "#model.conv2.conv.weight.data[:32,:32] = torch.from_numpy(arn_weight).cuda()\n",
    "validate(val_loader, model, criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2be79e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time \n",
    "import numpy as np\n",
    "\n",
    "model = models.resnet18(pretrained=True)\n",
    "model = model.cuda()\n",
    "\n",
    "\n",
    "#layer 17\n",
    "weight = model.layer4[1].conv2.weight\n",
    "weight_half = weight[:512,:512]\n",
    "print('layer half weights size is: ',weight_half.size())\n",
    "weight_numpy = weight_half.detach().cpu().numpy()\n",
    "start = time.time()\n",
    "arn_weight = arnold(weight_numpy,[1, 1,1,1,2])\n",
    "end = time.time()\n",
    "total = end - start\n",
    "# print('the difference is',np.count_nonzero(weight_numpy-arn_weight))\n",
    "print('need {:.6f} sec'.format(total))\n",
    "\n",
    "model.layer4[1].conv2.weight.data[:512,:512] = torch.from_numpy(arn_weight).cuda()\n",
    "#model.layer3[0].conv2.weight.data[:192,:192] = torch.from_numpy(arn_weight).cuda()\n",
    "#model.conv2.conv.weight.data[:32,:32] = torch.from_numpy(arn_weight).cuda()\n",
    "validate(val_loader, model, criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86cdc1da",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-torch1.10.2]",
   "language": "python",
   "name": "conda-env-.conda-torch1.10.2-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
