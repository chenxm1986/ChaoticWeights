{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3870ba7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import shutil\n",
    "import time\n",
    "import warnings\n",
    "#os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"5\"\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.distributed as dist\n",
    "import torch.optim\n",
    "import torch.multiprocessing as mp\n",
    "import torch.utils.data\n",
    "import torch.utils.data.distributed\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.models as models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c864e626",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data loading code\n",
    "\n",
    "##!!!! change the valdir to your data path\n",
    "valdir = '/data/public/imagenet2012/val'\n",
    "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                 std=[0.229, 0.224, 0.225])\n",
    "\n",
    "batch_size = 256\n",
    "val_loader = torch.utils.data.DataLoader(\n",
    "    datasets.ImageFolder(valdir, transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        normalize,\n",
    "    ])),\n",
    "    batch_size=batch_size, shuffle=False,\n",
    "    num_workers=4, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0fc5babb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(val_loader, model, criterion):\n",
    "    batch_time = AverageMeter('Time', ':6.3f')\n",
    "    losses = AverageMeter('Loss', ':.4e')\n",
    "    top1 = AverageMeter('Acc@1', ':6.2f')\n",
    "    top5 = AverageMeter('Acc@5', ':6.2f')\n",
    "    progress = ProgressMeter(\n",
    "        len(val_loader),\n",
    "        [batch_time, losses, top1, top5],\n",
    "        prefix='Test: ')\n",
    "\n",
    "    # switch to evaluate mode\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        end = time.time()\n",
    "        for i, (images, target) in enumerate(val_loader):\n",
    "           \n",
    "            images = images.cuda()\n",
    "            target = target.cuda()\n",
    "\n",
    "            # compute output\n",
    "            output = model(images)\n",
    "            loss = criterion(output, target)\n",
    "\n",
    "            # measure accuracy and record loss\n",
    "            acc1, acc5 = accuracy(output, target, topk=(1, 5))\n",
    "            losses.update(loss.item(), images.size(0))\n",
    "            top1.update(acc1[0], images.size(0))\n",
    "            top5.update(acc5[0], images.size(0))\n",
    "\n",
    "            # measure elapsed time\n",
    "            batch_time.update(time.time() - end)\n",
    "            end = time.time()\n",
    "\n",
    "            if i % 10 == 0:\n",
    "                progress.display(i)\n",
    "\n",
    "        # TODO: this should also be done with the ProgressMeter\n",
    "        print(' * Acc@1 {top1.avg:.3f} Acc@5 {top5.avg:.3f}'\n",
    "              .format(top1=top1, top5=top5))\n",
    "\n",
    "    return top1.avg\n",
    "\n",
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "    def __init__(self, name, fmt=':f'):\n",
    "        self.name = name\n",
    "        self.fmt = fmt\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "    def __str__(self):\n",
    "        fmtstr = '{name} {val' + self.fmt + '} ({avg' + self.fmt + '})'\n",
    "        return fmtstr.format(**self.__dict__)\n",
    "\n",
    "\n",
    "class ProgressMeter(object):\n",
    "    def __init__(self, num_batches, meters, prefix=\"\"):\n",
    "        self.batch_fmtstr = self._get_batch_fmtstr(num_batches)\n",
    "        self.meters = meters\n",
    "        self.prefix = prefix\n",
    "\n",
    "    def display(self, batch):\n",
    "        entries = [self.prefix + self.batch_fmtstr.format(batch)]\n",
    "        entries += [str(meter) for meter in self.meters]\n",
    "        print('\\t'.join(entries))\n",
    "\n",
    "    def _get_batch_fmtstr(self, num_batches):\n",
    "        num_digits = len(str(num_batches // 1))\n",
    "        fmt = '{:' + str(num_digits) + 'd}'\n",
    "        return '[' + fmt + '/' + fmt.format(num_batches) + ']'\n",
    "    \n",
    "def accuracy(output, target, topk=(1,)):\n",
    "    \"\"\"Computes the accuracy over the k top predictions for the specified values of k\"\"\"\n",
    "    with torch.no_grad():\n",
    "        maxk = max(topk)\n",
    "        batch_size = target.size(0)\n",
    "\n",
    "        _, pred = output.topk(maxk, 1, True, True)\n",
    "        pred = pred.t()\n",
    "        correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
    "\n",
    "        res = []\n",
    "        for k in topk:\n",
    "            correct_k = correct[:k].contiguous().view(-1).float().sum(0, keepdim=True)\n",
    "            res.append(correct_k.mul_(100.0 / batch_size))\n",
    "        return res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68f6b20a",
   "metadata": {},
   "source": [
    "##  Arnold and iArnold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9e02030d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "def arnold(img, key):\n",
    "    N, a, b, c, d = key  #  key=[1,1,1,1,2]\n",
    "    h, w = img.shape[: 2]\n",
    "    new_img = copy.deepcopy(img)\n",
    "\n",
    "    for i in range(N):\n",
    "        \n",
    "        for x in range(h):\n",
    "            \n",
    "            for y in range(w):\n",
    "                \n",
    "                nx = ((a * x + b * y) % w + w) % w\n",
    "                ny = ((c * x + d * y) % w + w) % w\n",
    "                nx = int(nx)\n",
    "                \n",
    "                ny = int(ny)\n",
    "                \n",
    "                new_img[nx, ny] = img[x, y]\n",
    "        img = copy.deepcopy(new_img)\n",
    "    return new_img\n",
    "\n",
    "\n",
    "def iarnold(img, key):\n",
    "    N, a, b, c, d = key\n",
    "    #matrix = np.mat([[a, b], [c, d]]).I\n",
    "    [[a, b], [c, d]] = [[(a*b+1),-a],[-b,1]]\n",
    "    return arnold(img, [N, a, b, c, d])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cbf972f",
   "metadata": {},
   "source": [
    "## Load a pre-trained model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5068b02c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.models as models\n",
    "\n",
    "\n",
    "\n",
    "vgg16 = models.vgg16(pretrained=True)\n",
    "\n",
    "# resnet18 = models.resnet18(pretrained=True)\n",
    "#densenet = models.densenet121(pretrained=True)\n",
    "#inception = models.inception_v3(pretrained=True)\n",
    "# googlenet = models.googlenet(pretrained=True)\n",
    "#shufflenet = models.shufflenet_v2_x1_0(pretrained=True)\n",
    "#mobilenet = models.mobilenet_v2(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "96587596",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features.0.weight      torch.Size([64, 3, 3, 3])\n",
      "features.0.bias      torch.Size([64])\n",
      "features.2.weight      torch.Size([64, 64, 3, 3])\n",
      "features.2.bias      torch.Size([64])\n",
      "features.5.weight      torch.Size([128, 64, 3, 3])\n",
      "features.5.bias      torch.Size([128])\n",
      "features.7.weight      torch.Size([128, 128, 3, 3])\n",
      "features.7.bias      torch.Size([128])\n",
      "features.10.weight      torch.Size([256, 128, 3, 3])\n",
      "features.10.bias      torch.Size([256])\n",
      "features.12.weight      torch.Size([256, 256, 3, 3])\n",
      "features.12.bias      torch.Size([256])\n",
      "features.14.weight      torch.Size([256, 256, 3, 3])\n",
      "features.14.bias      torch.Size([256])\n",
      "features.17.weight      torch.Size([512, 256, 3, 3])\n",
      "features.17.bias      torch.Size([512])\n",
      "features.19.weight      torch.Size([512, 512, 3, 3])\n",
      "features.19.bias      torch.Size([512])\n",
      "features.21.weight      torch.Size([512, 512, 3, 3])\n",
      "features.21.bias      torch.Size([512])\n",
      "features.24.weight      torch.Size([512, 512, 3, 3])\n",
      "features.24.bias      torch.Size([512])\n",
      "features.26.weight      torch.Size([512, 512, 3, 3])\n",
      "features.26.bias      torch.Size([512])\n",
      "features.28.weight      torch.Size([512, 512, 3, 3])\n",
      "features.28.bias      torch.Size([512])\n",
      "classifier.0.weight      torch.Size([4096, 25088])\n",
      "classifier.0.bias      torch.Size([4096])\n",
      "classifier.3.weight      torch.Size([4096, 4096])\n",
      "classifier.3.bias      torch.Size([4096])\n",
      "classifier.6.weight      torch.Size([1000, 4096])\n",
      "classifier.6.bias      torch.Size([1000])\n",
      "Test: [  0/196]\tTime  2.858 ( 2.858)\tLoss 5.8757e-01 (5.8757e-01)\tAcc@1  86.72 ( 86.72)\tAcc@5  96.48 ( 96.48)\n",
      "Test: [ 10/196]\tTime  0.266 ( 0.799)\tLoss 1.0640e+00 (7.9315e-01)\tAcc@1  70.70 ( 79.58)\tAcc@5  92.58 ( 94.28)\n",
      "Test: [ 20/196]\tTime  3.045 ( 0.921)\tLoss 8.5919e-01 (8.1192e-01)\tAcc@1  81.25 ( 79.35)\tAcc@5  91.41 ( 94.08)\n",
      "Test: [ 30/196]\tTime  0.265 ( 0.964)\tLoss 8.1008e-01 (7.8327e-01)\tAcc@1  78.91 ( 80.19)\tAcc@5  94.53 ( 94.20)\n",
      "Test: [ 40/196]\tTime  2.577 ( 0.970)\tLoss 7.9159e-01 (8.2898e-01)\tAcc@1  78.52 ( 78.33)\tAcc@5  96.09 ( 94.26)\n",
      "Test: [ 50/196]\tTime  0.267 ( 0.917)\tLoss 5.2302e-01 (8.2114e-01)\tAcc@1  86.33 ( 78.44)\tAcc@5  97.66 ( 94.58)\n",
      "Test: [ 60/196]\tTime  2.482 ( 0.926)\tLoss 1.1568e+00 (8.3607e-01)\tAcc@1  68.36 ( 77.88)\tAcc@5  91.41 ( 94.58)\n",
      "Test: [ 70/196]\tTime  0.267 ( 0.905)\tLoss 8.9274e-01 (8.2239e-01)\tAcc@1  77.73 ( 78.28)\tAcc@5  92.58 ( 94.67)\n",
      "Test: [ 80/196]\tTime  2.595 ( 0.915)\tLoss 1.6939e+00 (8.4822e-01)\tAcc@1  59.38 ( 77.80)\tAcc@5  87.50 ( 94.34)\n",
      "Test: [ 90/196]\tTime  0.269 ( 0.898)\tLoss 2.2399e+00 (9.1129e-01)\tAcc@1  55.47 ( 76.62)\tAcc@5  79.30 ( 93.56)\n",
      "Test: [100/196]\tTime  2.308 ( 0.898)\tLoss 1.5257e+00 (9.7139e-01)\tAcc@1  60.55 ( 75.20)\tAcc@5  87.11 ( 92.81)\n",
      "Test: [110/196]\tTime  0.268 ( 0.889)\tLoss 1.1546e+00 (9.9738e-01)\tAcc@1  72.66 ( 74.72)\tAcc@5  90.62 ( 92.44)\n",
      "Test: [120/196]\tTime  2.506 ( 0.896)\tLoss 1.5908e+00 (1.0213e+00)\tAcc@1  63.67 ( 74.33)\tAcc@5  83.20 ( 92.08)\n",
      "Test: [130/196]\tTime  0.269 ( 0.884)\tLoss 9.0341e-01 (1.0576e+00)\tAcc@1  79.69 ( 73.47)\tAcc@5  92.97 ( 91.65)\n",
      "Test: [140/196]\tTime  2.376 ( 0.886)\tLoss 1.2805e+00 (1.0789e+00)\tAcc@1  68.36 ( 73.07)\tAcc@5  85.94 ( 91.35)\n",
      "Test: [150/196]\tTime  0.268 ( 0.874)\tLoss 1.1372e+00 (1.1000e+00)\tAcc@1  75.78 ( 72.64)\tAcc@5  88.67 ( 90.96)\n",
      "Test: [160/196]\tTime  2.405 ( 0.880)\tLoss 9.5388e-01 (1.1163e+00)\tAcc@1  76.56 ( 72.33)\tAcc@5  92.97 ( 90.69)\n",
      "Test: [170/196]\tTime  0.269 ( 0.873)\tLoss 7.2430e-01 (1.1370e+00)\tAcc@1  80.86 ( 71.84)\tAcc@5  95.70 ( 90.43)\n",
      "Test: [180/196]\tTime  2.509 ( 0.879)\tLoss 1.3201e+00 (1.1532e+00)\tAcc@1  64.84 ( 71.47)\tAcc@5  92.58 ( 90.28)\n",
      "Test: [190/196]\tTime  0.269 ( 0.871)\tLoss 1.2596e+00 (1.1520e+00)\tAcc@1  63.67 ( 71.45)\tAcc@5  92.97 ( 90.33)\n",
      " * Acc@1 71.594 Acc@5 90.384\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(71.5940, device='cuda:0')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torchvision.models as models\n",
    "cudnn.benchmark = True\n",
    "criterion = nn.CrossEntropyLoss().cuda()\n",
    "\n",
    "# change this model\n",
    "# model = models.googlenet(pretrained=True)\n",
    "#model = models.resnet101(pretrained=True)\n",
    "#model = models.mobilenet_v2(pretrained=True)\n",
    "#model = models.densenet121(pretrained=True)\n",
    "\n",
    "model = models.vgg16(pretrained=True)\n",
    "model = model.cuda()\n",
    "\n",
    "# 每层名字\n",
    "for name, param in model.named_parameters():\n",
    "    print(name,'    ', param.size())\n",
    "\n",
    "\n",
    "\n",
    "## test the original accuracy\n",
    "validate(val_loader, model, criterion) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "716e084f",
   "metadata": {},
   "source": [
    "## Encryption"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a2419f4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer half weights size is:  torch.Size([3, 3, 3, 3])\n",
      "need 0.000163 sec in python\n",
      "Test: [  0/196]\tTime  2.962 ( 2.962)\tLoss 5.8738e-01 (5.8738e-01)\tAcc@1  85.16 ( 85.16)\tAcc@5  96.88 ( 96.88)\n",
      "Test: [ 10/196]\tTime  0.267 ( 0.826)\tLoss 1.1062e+00 (8.5168e-01)\tAcc@1  71.48 ( 78.30)\tAcc@5  92.97 ( 94.00)\n",
      "Test: [ 20/196]\tTime  2.391 ( 0.892)\tLoss 9.2269e-01 (8.6629e-01)\tAcc@1  80.86 ( 78.12)\tAcc@5  92.58 ( 93.84)\n",
      "Test: [ 30/196]\tTime  0.267 ( 0.865)\tLoss 8.3381e-01 (8.3661e-01)\tAcc@1  78.52 ( 78.84)\tAcc@5  94.14 ( 93.93)\n",
      "Test: [ 40/196]\tTime  1.925 ( 0.960)\tLoss 8.9920e-01 (8.9030e-01)\tAcc@1  76.17 ( 76.82)\tAcc@5  94.92 ( 93.70)\n",
      "Test: [ 50/196]\tTime  1.005 ( 1.044)\tLoss 4.8227e-01 (8.8155e-01)\tAcc@1  86.33 ( 76.91)\tAcc@5  97.27 ( 93.96)\n",
      "Test: [ 60/196]\tTime  0.540 ( 1.036)\tLoss 1.2319e+00 (8.9501e-01)\tAcc@1  69.14 ( 76.35)\tAcc@5  89.84 ( 93.97)\n",
      "Test: [ 70/196]\tTime  0.906 ( 1.048)\tLoss 1.0618e+00 (8.8639e-01)\tAcc@1  72.66 ( 76.71)\tAcc@5  90.62 ( 93.96)\n",
      "Test: [ 80/196]\tTime  0.786 ( 1.040)\tLoss 1.7404e+00 (9.0972e-01)\tAcc@1  58.59 ( 76.37)\tAcc@5  86.33 ( 93.69)\n",
      "Test: [ 90/196]\tTime  2.943 ( 1.057)\tLoss 2.2560e+00 (9.7335e-01)\tAcc@1  53.52 ( 75.06)\tAcc@5  78.52 ( 92.84)\n",
      "Test: [100/196]\tTime  0.321 ( 1.045)\tLoss 1.6620e+00 (1.0316e+00)\tAcc@1  56.64 ( 73.77)\tAcc@5  83.98 ( 92.09)\n",
      "Test: [110/196]\tTime  2.586 ( 1.058)\tLoss 1.2369e+00 (1.0590e+00)\tAcc@1  68.36 ( 73.23)\tAcc@5  91.02 ( 91.74)\n",
      "Test: [120/196]\tTime  0.616 ( 1.038)\tLoss 1.6833e+00 (1.0833e+00)\tAcc@1  62.11 ( 72.86)\tAcc@5  80.47 ( 91.33)\n",
      "Test: [130/196]\tTime  2.938 ( 1.035)\tLoss 9.7181e-01 (1.1184e+00)\tAcc@1  77.73 ( 72.02)\tAcc@5  91.41 ( 90.91)\n",
      "Test: [140/196]\tTime  0.269 ( 1.029)\tLoss 1.3184e+00 (1.1402e+00)\tAcc@1  69.14 ( 71.64)\tAcc@5  86.72 ( 90.59)\n",
      "Test: [150/196]\tTime  3.747 ( 1.046)\tLoss 1.2064e+00 (1.1606e+00)\tAcc@1  73.44 ( 71.24)\tAcc@5  87.11 ( 90.19)\n",
      "Test: [160/196]\tTime  0.268 ( 1.042)\tLoss 9.8991e-01 (1.1763e+00)\tAcc@1  77.34 ( 70.97)\tAcc@5  91.80 ( 89.94)\n",
      "Test: [170/196]\tTime  3.002 ( 1.043)\tLoss 7.9295e-01 (1.1971e+00)\tAcc@1  78.12 ( 70.49)\tAcc@5  94.53 ( 89.63)\n",
      "Test: [180/196]\tTime  0.269 ( 1.026)\tLoss 1.3096e+00 (1.2119e+00)\tAcc@1  66.41 ( 70.17)\tAcc@5  92.97 ( 89.50)\n",
      "Test: [190/196]\tTime  2.310 ( 1.022)\tLoss 1.2547e+00 (1.2112e+00)\tAcc@1  64.06 ( 70.18)\tAcc@5  91.80 ( 89.54)\n",
      " * Acc@1 70.356 Acc@5 89.582\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(70.3560, device='cuda:0')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import time \n",
    "import numpy as np\n",
    "\n",
    "# layer 1\n",
    "weight = model.features[0].weight\n",
    "weight_half = weight[:3,:3]\n",
    "print('layer half weights size is: ',weight_half.size())\n",
    "weight_numpy = weight_half.detach().cpu().numpy()\n",
    "start = time.time()\n",
    "arn_weight = arnold(weight_numpy,[1, 1,1,1,2])\n",
    "end = time.time()\n",
    "total = end - start\n",
    "# print('the difference is',np.count_nonzero(weight_numpy-arn_weight))\n",
    "print('need {:.6f} sec in python'.format(total))\n",
    "\n",
    "model.features[0].weight.data[:3,:3] = torch.from_numpy(arn_weight).cuda()\n",
    "#model.layer3[0].conv2.weight.data[:192,:192] = torch.from_numpy(arn_weight).cuda()\n",
    "#model.conv2.conv.weight.data[:32,:32] = torch.from_numpy(arn_weight).cuda()\n",
    "validate(val_loader, model, criterion)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "743e14fb",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer half weights size is:  torch.Size([64, 64, 3, 3])\n",
      "need 0.004971 sec in python\n",
      "Test: [  0/196]\tTime  2.781 ( 2.781)\tLoss 9.8434e+00 (9.8434e+00)\tAcc@1   0.00 (  0.00)\tAcc@5   0.00 (  0.00)\n",
      "Test: [ 10/196]\tTime  0.282 ( 0.872)\tLoss 9.5547e+00 (1.0004e+01)\tAcc@1   0.00 (  0.07)\tAcc@5   0.00 (  0.14)\n",
      "Test: [ 20/196]\tTime  2.747 ( 1.087)\tLoss 1.0233e+01 (9.7589e+00)\tAcc@1   0.00 (  0.06)\tAcc@5   0.00 (  0.26)\n",
      "Test: [ 30/196]\tTime  0.269 ( 1.133)\tLoss 9.7170e+00 (9.8220e+00)\tAcc@1   0.00 (  0.04)\tAcc@5   0.00 (  0.20)\n",
      "Test: [ 40/196]\tTime  3.225 ( 1.171)\tLoss 1.0688e+01 (1.0043e+01)\tAcc@1   0.00 (  0.03)\tAcc@5   0.00 (  0.15)\n",
      "Test: [ 50/196]\tTime  0.368 ( 1.159)\tLoss 8.6379e+00 (1.0060e+01)\tAcc@1   0.00 (  0.02)\tAcc@5   0.00 (  0.12)\n",
      "Test: [ 60/196]\tTime  1.438 ( 1.180)\tLoss 7.7788e+00 (9.9459e+00)\tAcc@1   0.00 (  0.02)\tAcc@5   0.00 (  0.10)\n",
      "Test: [ 70/196]\tTime  0.268 ( 1.214)\tLoss 9.7044e+00 (9.9197e+00)\tAcc@1   0.00 (  0.02)\tAcc@5   0.00 (  0.10)\n",
      "Test: [ 80/196]\tTime  2.725 ( 1.211)\tLoss 1.0660e+01 (9.9237e+00)\tAcc@1   0.00 (  0.02)\tAcc@5   0.39 (  0.14)\n",
      "Test: [ 90/196]\tTime  0.489 ( 1.176)\tLoss 9.7725e+00 (9.8506e+00)\tAcc@1   0.00 (  0.05)\tAcc@5   0.00 (  0.21)\n",
      "Test: [100/196]\tTime  1.298 ( 1.174)\tLoss 9.3966e+00 (9.7627e+00)\tAcc@1   0.00 (  0.13)\tAcc@5   0.00 (  0.42)\n",
      "Test: [110/196]\tTime  0.320 ( 1.158)\tLoss 8.9272e+00 (9.6753e+00)\tAcc@1   0.00 (  0.12)\tAcc@5   0.39 (  0.50)\n",
      "Test: [120/196]\tTime  1.654 ( 1.160)\tLoss 8.8911e+00 (9.6281e+00)\tAcc@1   0.00 (  0.11)\tAcc@5   2.73 (  0.52)\n",
      "Test: [130/196]\tTime  0.270 ( 1.140)\tLoss 8.0360e+00 (9.5498e+00)\tAcc@1   0.00 (  0.21)\tAcc@5   0.39 (  0.80)\n",
      "Test: [140/196]\tTime  0.678 ( 1.130)\tLoss 8.7528e+00 (9.5089e+00)\tAcc@1   0.00 (  0.20)\tAcc@5   0.00 (  0.76)\n",
      "Test: [150/196]\tTime  0.268 ( 1.099)\tLoss 9.5096e+00 (9.4609e+00)\tAcc@1   0.00 (  0.19)\tAcc@5   0.00 (  0.74)\n",
      "Test: [160/196]\tTime  1.363 ( 1.095)\tLoss 9.3748e+00 (9.4285e+00)\tAcc@1   0.00 (  0.20)\tAcc@5   0.00 (  0.85)\n",
      "Test: [170/196]\tTime  0.267 ( 1.093)\tLoss 9.4792e+00 (9.3944e+00)\tAcc@1   0.00 (  0.19)\tAcc@5   0.00 (  0.86)\n",
      "Test: [180/196]\tTime  1.462 ( 1.115)\tLoss 7.3148e+00 (9.3356e+00)\tAcc@1   4.69 (  0.22)\tAcc@5  13.28 (  0.94)\n",
      "Test: [190/196]\tTime  0.267 ( 1.110)\tLoss 8.5081e+00 (9.2936e+00)\tAcc@1   0.39 (  0.21)\tAcc@5   1.95 (  0.95)\n",
      " * Acc@1 0.206 Acc@5 0.938\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(0.2060, device='cuda:0')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#layer 2\n",
    "model = models.vgg16(pretrained=True)\n",
    "model = model.cuda()\n",
    "    \n",
    "\n",
    "weight = model.features[2].weight\n",
    "weight_half = weight[:64,:64]\n",
    "print('layer half weights size is: ',weight_half.size())\n",
    "weight_numpy = weight_half.detach().cpu().numpy()\n",
    "start = time.time()\n",
    "arn_weight = arnold(weight_numpy,[1, 1,1,1,2])\n",
    "end = time.time()\n",
    "total = end - start\n",
    "# print('the difference is',np.count_nonzero(weight_numpy-arn_weight))\n",
    "print('need {:.6f} sec in python'.format(total))\n",
    "\n",
    "model.features[2].weight.data[:64,:64] = torch.from_numpy(arn_weight).cuda()\n",
    "#model.layer3[0].conv2.weight.data[:192,:192] = torch.from_numpy(arn_weight).cuda()\n",
    "#model.conv2.conv.weight.data[:32,:32] = torch.from_numpy(arn_weight).cuda()\n",
    "validate(val_loader, model, criterion)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "daa165cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer half weights size is:  torch.Size([64, 64, 3, 3])\n",
      "need 0.004946 sec in python\n",
      "Test: [  0/196]\tTime  4.327 ( 4.327)\tLoss 2.7252e+00 (2.7252e+00)\tAcc@1  47.66 ( 47.66)\tAcc@5  66.02 ( 66.02)\n",
      "Test: [ 10/196]\tTime  0.269 ( 1.082)\tLoss 2.2212e+00 (2.9396e+00)\tAcc@1  44.92 ( 38.07)\tAcc@5  75.00 ( 62.71)\n",
      "Test: [ 20/196]\tTime  2.278 ( 1.020)\tLoss 4.0896e+00 (2.6570e+00)\tAcc@1  23.05 ( 42.54)\tAcc@5  42.19 ( 67.32)\n",
      "Test: [ 30/196]\tTime  0.269 ( 0.947)\tLoss 1.4247e+00 (2.7020e+00)\tAcc@1  63.67 ( 42.54)\tAcc@5  87.50 ( 66.44)\n",
      "Test: [ 40/196]\tTime  2.137 ( 0.961)\tLoss 2.9775e+00 (2.7229e+00)\tAcc@1  40.23 ( 41.30)\tAcc@5  63.67 ( 66.31)\n",
      "Test: [ 50/196]\tTime  0.269 ( 0.915)\tLoss 1.6722e+00 (2.6890e+00)\tAcc@1  64.84 ( 41.84)\tAcc@5  83.20 ( 67.19)\n",
      "Test: [ 60/196]\tTime  2.304 ( 0.937)\tLoss 2.7069e+00 (2.7076e+00)\tAcc@1  33.59 ( 41.28)\tAcc@5  69.14 ( 66.95)\n",
      "Test: [ 70/196]\tTime  0.279 ( 0.917)\tLoss 3.0455e+00 (2.6949e+00)\tAcc@1  37.11 ( 41.84)\tAcc@5  61.33 ( 67.16)\n",
      "Test: [ 80/196]\tTime  2.416 ( 0.944)\tLoss 3.2306e+00 (2.6819e+00)\tAcc@1  31.25 ( 41.88)\tAcc@5  57.81 ( 67.26)\n",
      "Test: [ 90/196]\tTime  0.269 ( 0.932)\tLoss 3.2871e+00 (2.6921e+00)\tAcc@1  28.52 ( 41.83)\tAcc@5  57.03 ( 67.12)\n",
      "Test: [100/196]\tTime  2.191 ( 0.927)\tLoss 3.0013e+00 (2.7050e+00)\tAcc@1  34.38 ( 41.56)\tAcc@5  61.33 ( 66.94)\n",
      "Test: [110/196]\tTime  0.269 ( 0.922)\tLoss 2.1676e+00 (2.6983e+00)\tAcc@1  51.95 ( 41.85)\tAcc@5  76.56 ( 67.11)\n",
      "Test: [120/196]\tTime  3.132 ( 0.934)\tLoss 2.5805e+00 (2.6878e+00)\tAcc@1  45.70 ( 42.10)\tAcc@5  67.19 ( 67.20)\n",
      "Test: [130/196]\tTime  0.269 ( 0.923)\tLoss 1.8459e+00 (2.6953e+00)\tAcc@1  61.72 ( 41.88)\tAcc@5  78.12 ( 67.10)\n",
      "Test: [140/196]\tTime  3.261 ( 0.931)\tLoss 2.5323e+00 (2.7038e+00)\tAcc@1  45.70 ( 41.81)\tAcc@5  67.19 ( 66.95)\n",
      "Test: [150/196]\tTime  0.268 ( 0.934)\tLoss 2.4714e+00 (2.7083e+00)\tAcc@1  50.00 ( 41.71)\tAcc@5  70.70 ( 66.86)\n",
      "Test: [160/196]\tTime  3.007 ( 0.953)\tLoss 3.6183e+00 (2.7088e+00)\tAcc@1  24.22 ( 41.72)\tAcc@5  50.00 ( 66.92)\n",
      "Test: [170/196]\tTime  0.268 ( 0.945)\tLoss 2.4172e+00 (2.7233e+00)\tAcc@1  47.66 ( 41.42)\tAcc@5  75.39 ( 66.65)\n",
      "Test: [180/196]\tTime  3.809 ( 0.971)\tLoss 2.9716e+00 (2.7264e+00)\tAcc@1  33.20 ( 41.44)\tAcc@5  62.11 ( 66.60)\n",
      "Test: [190/196]\tTime  0.268 ( 0.967)\tLoss 3.5536e+00 (2.7599e+00)\tAcc@1  18.36 ( 40.84)\tAcc@5  50.00 ( 65.99)\n",
      " * Acc@1 40.892 Acc@5 66.056\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(40.8920, device='cuda:0')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#layer 3\n",
    "model = models.vgg16(pretrained=True)\n",
    "model = model.cuda()\n",
    "    \n",
    "\n",
    "weight = model.features[5].weight\n",
    "weight_half = weight[:64,:64]\n",
    "print('layer half weights size is: ',weight_half.size())\n",
    "weight_numpy = weight_half.detach().cpu().numpy()\n",
    "start = time.time()\n",
    "arn_weight = arnold(weight_numpy,[1, 1,1,1,2])\n",
    "end = time.time()\n",
    "total = end - start\n",
    "# print('the difference is',np.count_nonzero(weight_numpy-arn_weight))\n",
    "print('need {:.6f} sec in python'.format(total))\n",
    "\n",
    "model.features[5].weight.data[:64,:64] = torch.from_numpy(arn_weight).cuda()\n",
    "#model.layer3[0].conv2.weight.data[:192,:192] = torch.from_numpy(arn_weight).cuda()\n",
    "#model.conv2.conv.weight.data[:32,:32] = torch.from_numpy(arn_weight).cuda()\n",
    "validate(val_loader, model, criterion) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f8da14de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer half weights size is:  torch.Size([128, 128, 3, 3])\n",
      "need 0.019129 sec in python\n",
      "Test: [  0/196]\tTime  4.085 ( 4.085)\tLoss 7.9026e+00 (7.9026e+00)\tAcc@1   0.00 (  0.00)\tAcc@5   0.00 (  0.00)\n",
      "Test: [ 10/196]\tTime  0.268 ( 1.082)\tLoss 8.9828e+00 (9.0160e+00)\tAcc@1   0.00 (  0.00)\tAcc@5   0.00 (  0.00)\n",
      "Test: [ 20/196]\tTime  0.268 ( 0.967)\tLoss 8.2030e+00 (8.5999e+00)\tAcc@1   0.00 (  0.02)\tAcc@5   0.00 (  0.17)\n",
      "Test: [ 30/196]\tTime  2.633 ( 1.033)\tLoss 7.4428e+00 (8.5567e+00)\tAcc@1   0.00 (  0.03)\tAcc@5   0.00 (  0.15)\n",
      "Test: [ 40/196]\tTime  0.267 ( 0.992)\tLoss 8.5604e+00 (8.4831e+00)\tAcc@1   0.00 (  0.02)\tAcc@5   0.00 (  0.11)\n",
      "Test: [ 50/196]\tTime  3.459 ( 1.015)\tLoss 8.0516e+00 (8.4540e+00)\tAcc@1   0.00 (  0.02)\tAcc@5   0.00 (  0.09)\n",
      "Test: [ 60/196]\tTime  0.268 ( 0.984)\tLoss 9.0690e+00 (8.4374e+00)\tAcc@1   0.00 (  0.01)\tAcc@5   0.00 (  0.08)\n",
      "Test: [ 70/196]\tTime  2.949 ( 0.987)\tLoss 7.3611e+00 (8.4463e+00)\tAcc@1   0.00 (  0.01)\tAcc@5   0.00 (  0.07)\n",
      "Test: [ 80/196]\tTime  0.274 ( 0.973)\tLoss 8.0612e+00 (8.3935e+00)\tAcc@1   0.00 (  0.01)\tAcc@5   0.39 (  0.07)\n",
      "Test: [ 90/196]\tTime  3.351 ( 0.991)\tLoss 7.2778e+00 (8.3459e+00)\tAcc@1   0.00 (  0.01)\tAcc@5   0.00 (  0.09)\n",
      "Test: [100/196]\tTime  0.276 ( 0.972)\tLoss 8.4129e+00 (8.3084e+00)\tAcc@1   0.00 (  0.01)\tAcc@5   0.00 (  0.08)\n",
      "Test: [110/196]\tTime  3.156 ( 0.975)\tLoss 7.8125e+00 (8.2530e+00)\tAcc@1   0.00 (  0.02)\tAcc@5   0.00 (  0.21)\n",
      "Test: [120/196]\tTime  0.270 ( 0.957)\tLoss 7.5177e+00 (8.1940e+00)\tAcc@1   0.00 (  0.02)\tAcc@5   0.00 (  0.21)\n",
      "Test: [130/196]\tTime  2.883 ( 0.958)\tLoss 7.1695e+00 (8.1531e+00)\tAcc@1   3.52 (  0.09)\tAcc@5  12.50 (  0.45)\n",
      "Test: [140/196]\tTime  0.269 ( 0.952)\tLoss 8.4445e+00 (8.1206e+00)\tAcc@1   0.00 (  0.08)\tAcc@5   0.00 (  0.44)\n",
      "Test: [150/196]\tTime  1.893 ( 0.955)\tLoss 7.6162e+00 (8.0745e+00)\tAcc@1   0.00 (  0.08)\tAcc@5   0.00 (  0.47)\n",
      "Test: [160/196]\tTime  0.269 ( 0.951)\tLoss 8.0903e+00 (8.0378e+00)\tAcc@1   0.00 (  0.11)\tAcc@5   0.00 (  0.59)\n",
      "Test: [170/196]\tTime  3.001 ( 0.958)\tLoss 8.4260e+00 (8.0293e+00)\tAcc@1   0.00 (  0.10)\tAcc@5   0.00 (  0.58)\n",
      "Test: [180/196]\tTime  0.495 ( 0.950)\tLoss 7.7500e+00 (7.9972e+00)\tAcc@1   0.00 (  0.13)\tAcc@5   0.78 (  0.71)\n",
      "Test: [190/196]\tTime  1.648 ( 0.949)\tLoss 7.6040e+00 (8.0348e+00)\tAcc@1   0.00 (  0.12)\tAcc@5   0.00 (  0.67)\n",
      " * Acc@1 0.118 Acc@5 0.658\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(0.1180, device='cuda:0')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#layer 4\n",
    "model = models.vgg16(pretrained=True)\n",
    "model = model.cuda()\n",
    "    \n",
    "\n",
    "weight = model.features[7].weight\n",
    "weight_half = weight[:128,:128]\n",
    "print('layer half weights size is: ',weight_half.size())\n",
    "weight_numpy = weight_half.detach().cpu().numpy()\n",
    "start = time.time()\n",
    "arn_weight = arnold(weight_numpy,[1, 1,1,1,2])\n",
    "end = time.time()\n",
    "total = end - start\n",
    "# print('the difference is',np.count_nonzero(weight_numpy-arn_weight))\n",
    "print('need {:.6f} sec in python'.format(total))\n",
    "\n",
    "model.features[7].weight.data[:128,:128] = torch.from_numpy(arn_weight).cuda()\n",
    "#model.layer3[0].conv2.weight.data[:192,:192] = torch.from_numpy(arn_weight).cuda()\n",
    "#model.conv2.conv.weight.data[:32,:32] = torch.from_numpy(arn_weight).cuda()\n",
    "validate(val_loader, model, criterion) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d4eb84b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer half weights size is:  torch.Size([128, 128, 3, 3])\n",
      "need 0.019444 sec in python\n",
      "Test: [  0/196]\tTime  4.318 ( 4.318)\tLoss 1.6500e+00 (1.6500e+00)\tAcc@1  57.03 ( 57.03)\tAcc@5  85.55 ( 85.55)\n",
      "Test: [ 10/196]\tTime  0.269 ( 1.069)\tLoss 2.3517e+00 (3.0739e+00)\tAcc@1  41.80 ( 34.48)\tAcc@5  74.61 ( 59.69)\n",
      "Test: [ 20/196]\tTime  2.442 ( 0.964)\tLoss 3.5819e+00 (2.8832e+00)\tAcc@1  31.64 ( 38.36)\tAcc@5  48.44 ( 63.13)\n",
      "Test: [ 30/196]\tTime  0.269 ( 0.870)\tLoss 1.4662e+00 (2.9710e+00)\tAcc@1  64.06 ( 38.85)\tAcc@5  89.06 ( 62.01)\n",
      "Test: [ 40/196]\tTime  1.915 ( 0.855)\tLoss 2.9184e+00 (2.8452e+00)\tAcc@1  32.81 ( 39.41)\tAcc@5  64.84 ( 64.26)\n",
      "Test: [ 50/196]\tTime  0.268 ( 0.824)\tLoss 1.4824e+00 (2.7029e+00)\tAcc@1  63.67 ( 41.34)\tAcc@5  85.55 ( 66.93)\n",
      "Test: [ 60/196]\tTime  2.485 ( 0.837)\tLoss 4.1404e+00 (2.7521e+00)\tAcc@1  19.14 ( 40.69)\tAcc@5  40.23 ( 66.25)\n",
      "Test: [ 70/196]\tTime  0.270 ( 0.812)\tLoss 2.5396e+00 (2.7660e+00)\tAcc@1  46.88 ( 41.00)\tAcc@5  67.58 ( 65.98)\n",
      "Test: [ 80/196]\tTime  1.894 ( 0.818)\tLoss 3.7072e+00 (2.7773e+00)\tAcc@1  21.48 ( 40.87)\tAcc@5  49.22 ( 65.69)\n",
      "Test: [ 90/196]\tTime  0.269 ( 0.802)\tLoss 4.1224e+00 (2.8315e+00)\tAcc@1  20.70 ( 39.87)\tAcc@5  42.58 ( 64.78)\n",
      "Test: [100/196]\tTime  1.573 ( 0.801)\tLoss 4.1183e+00 (2.8980e+00)\tAcc@1  15.23 ( 38.69)\tAcc@5  41.80 ( 63.70)\n",
      "Test: [110/196]\tTime  0.269 ( 0.797)\tLoss 3.3272e+00 (2.9311e+00)\tAcc@1  35.55 ( 38.10)\tAcc@5  55.86 ( 63.14)\n",
      "Test: [120/196]\tTime  2.300 ( 0.809)\tLoss 3.0802e+00 (2.9513e+00)\tAcc@1  42.19 ( 37.96)\tAcc@5  63.28 ( 62.73)\n",
      "Test: [130/196]\tTime  0.273 ( 0.802)\tLoss 2.3455e+00 (2.9726e+00)\tAcc@1  52.34 ( 37.59)\tAcc@5  70.70 ( 62.40)\n",
      "Test: [140/196]\tTime  1.967 ( 0.805)\tLoss 2.4323e+00 (2.9823e+00)\tAcc@1  42.58 ( 37.48)\tAcc@5  71.48 ( 62.15)\n",
      "Test: [150/196]\tTime  0.301 ( 0.797)\tLoss 3.0189e+00 (2.9938e+00)\tAcc@1  36.72 ( 37.32)\tAcc@5  63.28 ( 61.90)\n",
      "Test: [160/196]\tTime  2.039 ( 0.804)\tLoss 3.0219e+00 (2.9949e+00)\tAcc@1  39.45 ( 37.25)\tAcc@5  60.55 ( 61.85)\n",
      "Test: [170/196]\tTime  0.269 ( 0.790)\tLoss 2.6826e+00 (3.0115e+00)\tAcc@1  43.75 ( 36.86)\tAcc@5  67.58 ( 61.57)\n",
      "Test: [180/196]\tTime  2.547 ( 0.796)\tLoss 4.3250e+00 (3.0266e+00)\tAcc@1  20.70 ( 36.71)\tAcc@5  36.33 ( 61.30)\n",
      "Test: [190/196]\tTime  0.384 ( 0.790)\tLoss 3.3378e+00 (3.0887e+00)\tAcc@1  20.31 ( 35.87)\tAcc@5  56.25 ( 60.34)\n",
      " * Acc@1 35.694 Acc@5 60.118\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(35.6940, device='cuda:0')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#layer 5\n",
    "model = models.vgg16(pretrained=True)\n",
    "model = model.cuda()\n",
    "    \n",
    "\n",
    "weight = model.features[10].weight\n",
    "weight_half = weight[:128,:128]\n",
    "print('layer half weights size is: ',weight_half.size())\n",
    "weight_numpy = weight_half.detach().cpu().numpy()\n",
    "start = time.time()\n",
    "arn_weight = arnold(weight_numpy,[1, 1,1,1,2])\n",
    "end = time.time()\n",
    "total = end - start\n",
    "# print('the difference is',np.count_nonzero(weight_numpy-arn_weight))\n",
    "print('need {:.6f} sec in python'.format(total))\n",
    "\n",
    "model.features[10].weight.data[:128,:128] = torch.from_numpy(arn_weight).cuda()\n",
    "#model.layer3[0].conv2.weight.data[:192,:192] = torch.from_numpy(arn_weight).cuda()\n",
    "#model.conv2.conv.weight.data[:32,:32] = torch.from_numpy(arn_weight).cuda()\n",
    "validate(val_loader, model, criterion) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea2c0283",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer half weights size is:  torch.Size([256, 256, 3, 3])\n",
      "need 0.087435 sec in python\n",
      "Test: [  0/196]\tTime  4.429 ( 4.429)\tLoss 8.1701e+00 (8.1701e+00)\tAcc@1   0.00 (  0.00)\tAcc@5   0.00 (  0.00)\n",
      "Test: [ 10/196]\tTime  0.268 ( 1.088)\tLoss 8.0704e+00 (8.5797e+00)\tAcc@1   0.00 (  0.00)\tAcc@5   0.00 (  0.00)\n",
      "Test: [ 20/196]\tTime  2.498 ( 1.013)\tLoss 8.4822e+00 (8.3706e+00)\tAcc@1   0.00 (  0.00)\tAcc@5   0.00 (  0.00)\n",
      "Test: [ 30/196]\tTime  0.269 ( 0.912)\tLoss 7.9334e+00 (8.4736e+00)\tAcc@1   0.00 (  0.00)\tAcc@5   0.00 (  0.00)\n",
      "Test: [ 40/196]\tTime  2.257 ( 0.914)\tLoss 8.4983e+00 (8.4014e+00)\tAcc@1   0.00 (  0.00)\tAcc@5   0.00 (  0.00)\n",
      "Test: [ 50/196]\tTime  0.326 ( 0.869)\tLoss 7.3078e+00 (8.3408e+00)\tAcc@1   0.00 (  0.00)\tAcc@5   0.00 (  0.00)\n"
     ]
    }
   ],
   "source": [
    "#layer 6\n",
    "model = models.vgg16(pretrained=True)\n",
    "model = model.cuda()\n",
    "    \n",
    "\n",
    "weight = model.features[12].weight\n",
    "weight_half = weight[:256,:256]\n",
    "print('layer half weights size is: ',weight_half.size())\n",
    "weight_numpy = weight_half.detach().cpu().numpy()\n",
    "start = time.time()\n",
    "arn_weight = arnold(weight_numpy,[1, 1,1,1,2])\n",
    "end = time.time()\n",
    "total = end - start\n",
    "# print('the difference is',np.count_nonzero(weight_numpy-arn_weight))\n",
    "print('need {:.6f} sec in python'.format(total))\n",
    "\n",
    "model.features[12].weight.data[:256,:256] = torch.from_numpy(arn_weight).cuda()\n",
    "#model.layer3[0].conv2.weight.data[:192,:192] = torch.from_numpy(arn_weight).cuda()\n",
    "#model.conv2.conv.weight.data[:32,:32] = torch.from_numpy(arn_weight).cuda()\n",
    "validate(val_loader, model, criterion) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be31f50c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#layer 7\n",
    "model = models.vgg16(pretrained=True)\n",
    "model = model.cuda()\n",
    "    \n",
    "\n",
    "weight = model.features[14].weight\n",
    "weight_half = weight[:256,:256]\n",
    "print('layer half weights size is: ',weight_half.size())\n",
    "weight_numpy = weight_half.detach().cpu().numpy()\n",
    "start = time.time()\n",
    "arn_weight = arnold(weight_numpy,[1, 1,1,1,2])\n",
    "end = time.time()\n",
    "total = end - start\n",
    "# print('the difference is',np.count_nonzero(weight_numpy-arn_weight))\n",
    "print('need {:.6f} sec in python'.format(total))\n",
    "\n",
    "model.features[14].weight.data[:256,:256] = torch.from_numpy(arn_weight).cuda()\n",
    "#model.layer3[0].conv2.weight.data[:192,:192] = torch.from_numpy(arn_weight).cuda()\n",
    "#model.conv2.conv.weight.data[:32,:32] = torch.from_numpy(arn_weight).cuda()\n",
    "validate(val_loader, model, criterion) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d2c90a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#layer 8\n",
    "model = models.vgg16(pretrained=True)\n",
    "model = model.cuda()\n",
    "    \n",
    "\n",
    "weight = model.features[17].weight\n",
    "weight_half = weight[:256,:256]\n",
    "print('layer half weights size is: ',weight_half.size())\n",
    "weight_numpy = weight_half.detach().cpu().numpy()\n",
    "start = time.time()\n",
    "arn_weight = arnold(weight_numpy,[1, 1,1,1,2])\n",
    "end = time.time()\n",
    "total = end - start\n",
    "# print('the difference is',np.count_nonzero(weight_numpy-arn_weight))\n",
    "print('need {:.6f} sec in python'.format(total))\n",
    "\n",
    "model.features[17].weight.data[:256,:256] = torch.from_numpy(arn_weight).cuda()\n",
    "#model.layer3[0].conv2.weight.data[:192,:192] = torch.from_numpy(arn_weight).cuda()\n",
    "#model.conv2.conv.weight.data[:32,:32] = torch.from_numpy(arn_weight).cuda()\n",
    "validate(val_loader, model, criterion) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d3a6542",
   "metadata": {},
   "outputs": [],
   "source": [
    "#layer 9\n",
    "model = models.vgg16(pretrained=True)\n",
    "model = model.cuda()\n",
    "    \n",
    "\n",
    "weight = model.features[19].weight\n",
    "weight_half = weight[:512,:512]\n",
    "print('layer half weights size is: ',weight_half.size())\n",
    "weight_numpy = weight_half.detach().cpu().numpy()\n",
    "start = time.time()\n",
    "arn_weight = arnold(weight_numpy,[1, 1,1,1,2])\n",
    "end = time.time()\n",
    "total = end - start\n",
    "# print('the difference is',np.count_nonzero(weight_numpy-arn_weight))\n",
    "print('need {:.6f} sec in python'.format(total))\n",
    "\n",
    "model.features[19].weight.data[:512,:512] = torch.from_numpy(arn_weight).cuda()\n",
    "#model.layer3[0].conv2.weight.data[:192,:192] = torch.from_numpy(arn_weight).cuda()\n",
    "#model.conv2.conv.weight.data[:32,:32] = torch.from_numpy(arn_weight).cuda()\n",
    "validate(val_loader, model, criterion) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8e281c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#layer 10\n",
    "model = models.vgg16(pretrained=True)\n",
    "model = model.cuda()\n",
    "    \n",
    "\n",
    "weight = model.features[21].weight\n",
    "weight_half = weight[:512,:512]\n",
    "print('layer half weights size is: ',weight_half.size())\n",
    "weight_numpy = weight_half.detach().cpu().numpy()\n",
    "start = time.time()\n",
    "arn_weight = arnold(weight_numpy,[1, 1,1,1,2])\n",
    "end = time.time()\n",
    "total = end - start\n",
    "# print('the difference is',np.count_nonzero(weight_numpy-arn_weight))\n",
    "print('need {:.6f} sec in python'.format(total))\n",
    "\n",
    "model.features[21].weight.data[:512,:512] = torch.from_numpy(arn_weight).cuda()\n",
    "#model.layer3[0].conv2.weight.data[:192,:192] = torch.from_numpy(arn_weight).cuda()\n",
    "#model.conv2.conv.weight.data[:32,:32] = torch.from_numpy(arn_weight).cuda()\n",
    "validate(val_loader, model, criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be018fc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#layer 11\n",
    "model = models.vgg16(pretrained=True)\n",
    "model = model.cuda()\n",
    "    \n",
    "\n",
    "weight = model.features[24].weight\n",
    "weight_half = weight[:512,:512]\n",
    "print('layer half weights size is: ',weight_half.size())\n",
    "weight_numpy = weight_half.detach().cpu().numpy()\n",
    "start = time.time()\n",
    "arn_weight = arnold(weight_numpy,[1, 1,1,1,2])\n",
    "end = time.time()\n",
    "total = end - start\n",
    "# print('the difference is',np.count_nonzero(weight_numpy-arn_weight))\n",
    "print('need {:.6f} sec in python'.format(total))\n",
    "\n",
    "model.features[24].weight.data[:512,:512] = torch.from_numpy(arn_weight).cuda()\n",
    "#model.layer3[0].conv2.weight.data[:192,:192] = torch.from_numpy(arn_weight).cuda()\n",
    "#model.conv2.conv.weight.data[:32,:32] = torch.from_numpy(arn_weight).cuda()\n",
    "validate(val_loader, model, criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51fec35a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#layer 12\n",
    "model = models.vgg16(pretrained=True)\n",
    "model = model.cuda()\n",
    "    \n",
    "\n",
    "weight = model.features[26].weight\n",
    "weight_half = weight[:512,:512]\n",
    "print('layer half weights size is: ',weight_half.size())\n",
    "weight_numpy = weight_half.detach().cpu().numpy()\n",
    "start = time.time()\n",
    "arn_weight = arnold(weight_numpy,[1, 1,1,1,2])\n",
    "end = time.time()\n",
    "total = end - start\n",
    "# print('the difference is',np.count_nonzero(weight_numpy-arn_weight))\n",
    "print('need {:.6f} sec in python'.format(total))\n",
    "\n",
    "model.features[26].weight.data[:512,:512] = torch.from_numpy(arn_weight).cuda()\n",
    "#model.layer3[0].conv2.weight.data[:192,:192] = torch.from_numpy(arn_weight).cuda()\n",
    "#model.conv2.conv.weight.data[:32,:32] = torch.from_numpy(arn_weight).cuda()\n",
    "validate(val_loader, model, criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "240d0397",
   "metadata": {},
   "outputs": [],
   "source": [
    "#laer 13\n",
    "model = models.vgg16(pretrained=True)\n",
    "model = model.cuda()\n",
    "    \n",
    "\n",
    "weight = model.features[28].weight\n",
    "weight_half = weight[:512,:512]\n",
    "print('layer half weights size is: ',weight_half.size())\n",
    "weight_numpy = weight_half.detach().cpu().numpy()\n",
    "start = time.time()\n",
    "arn_weight = arnold(weight_numpy,[1, 1,1,1,2])\n",
    "end = time.time()\n",
    "total = end - start\n",
    "# print('the difference is',np.count_nonzero(weight_numpy-arn_weight))\n",
    "print('need {:.6f} sec in python'.format(total))\n",
    "\n",
    "model.features[28].weight.data[:512,:512] = torch.from_numpy(arn_weight).cuda()\n",
    "#model.layer3[0].conv2.weight.data[:192,:192] = torch.from_numpy(arn_weight).cuda()\n",
    "#model.conv2.conv.weight.data[:32,:32] = torch.from_numpy(arn_weight).cuda()\n",
    "validate(val_loader, model, criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "486a5d78",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-torch1.10.2]",
   "language": "python",
   "name": "conda-env-.conda-torch1.10.2-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
